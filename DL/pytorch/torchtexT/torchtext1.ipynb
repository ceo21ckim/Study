{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install torchtext"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.10.0-cp37-cp37m-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\eonkim\\anaconda3\\envs\\default\\lib\\site-packages (from torchtext) (1.21.2)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp37-cp37m-win_amd64.whl (222.0 MB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\eonkim\\anaconda3\\envs\\default\\lib\\site-packages (from torch==1.9.0->torchtext) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eonkim\\anaconda3\\envs\\default\\lib\\site-packages (from requests->torchtext) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eonkim\\anaconda3\\envs\\default\\lib\\site-packages (from requests->torchtext) (1.26.6)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\eonkim\\anaconda3\\envs\\default\\lib\\site-packages (from tqdm->torchtext) (0.4.4)\n",
      "Installing collected packages: idna, charset-normalizer, tqdm, torch, requests, torchtext\n",
      "Successfully installed charset-normalizer-2.0.4 idna-3.2 requests-2.26.0 torch-1.9.0 torchtext-0.10.0 tqdm-4.62.2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from torchtext import data "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 코퍼스와 레이블 읽기\r\n",
    "class DataLoader(object):\r\n",
    "    def __init__(self, train_fn, valid_fn,\r\n",
    "                batch_size=64,\r\n",
    "                device=-1,\r\n",
    "                max_vocab=999999,\r\n",
    "                min_freq=1,\r\n",
    "                use_eos=False,\r\n",
    "                shuffle=True):\r\n",
    "\r\n",
    "        super(DataLoader, self).__init__()\r\n",
    "        \r\n",
    "\r\n",
    "        self.label = data.Field(sequential=False,\r\n",
    "                                use_vocab=True,\r\n",
    "                                unk_token=None\r\n",
    "                                )\r\n",
    "\r\n",
    "        self.text = data.Field(use_vocab=True,\r\n",
    "                               batch_first=True,\r\n",
    "                               include_lengths=False,\r\n",
    "                               eos_token='<EOS>' if use_eos else None\r\n",
    "                               )\r\n",
    "\r\n",
    "        \r\n",
    "        train, valid = data.TabularDataset.splits(path='',\r\n",
    "        train=train_fn,\r\n",
    "        validation=valid_fn,\r\n",
    "        format='tsv',\r\n",
    "        fields=[\r\n",
    "            ('label', self.label),\r\n",
    "            ('text', self.text)])\r\n",
    "\r\n",
    "        self.train_iter, self.valid_iter = data.BucketIterator.splits(\r\n",
    "            (train, valid),\r\n",
    "            batch_size=batch_size,\r\n",
    "            #device='cuda:%d' %device if device >= 0 else 'cpu'\r\n",
    "            shuffle=shuffle,\r\n",
    "            sort_key=lambda x: len(x.text),\r\n",
    "            sort_within_batch=True\r\n",
    "            )\r\n",
    "\r\n",
    "        self.label.build_vocab(train)\r\n",
    "        self.text.build.vocab(train, max_size=max_vocab, min_freq=min_freq)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# read corpus\r\n",
    "from torchtext import data, datasets\r\n",
    "\r\n",
    "\r\n",
    "PAD, BOS, EOS = 1, 2, 3\r\n",
    "\r\n",
    "class DataLoader():\r\n",
    "\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        train_fn,\r\n",
    "        valid_fn,\r\n",
    "        batch_size=64,\r\n",
    "        device='cpu',\r\n",
    "        max_vocab=999999,\r\n",
    "        max_length=255,\r\n",
    "        fix_length=None,\r\n",
    "        use_bos=True,\r\n",
    "        use_eos=True,\r\n",
    "        shuffle=True):\r\n",
    "\r\n",
    "\r\n",
    "        super(DataLoader, self).__init__()\r\n",
    "\r\n",
    "        self.text = data.Field(\r\n",
    "            sequential=True,\r\n",
    "            use_vocab=True,\r\n",
    "            batch_first=True,\r\n",
    "            include_lengths=True,\r\n",
    "            fix_length=fix_length,\r\n",
    "            init_token='<BOS>' if use_bos else None,\r\n",
    "            eos_token='<EOS>' if use_eos else None)\r\n",
    "\r\n",
    "\r\n",
    "        train = LanguageModelDataset(\r\n",
    "            path=train_fn,\r\n",
    "            fields=[('text', self.text)],\r\n",
    "            max_length=max_length\r\n",
    "        )\r\n",
    "\r\n",
    "        valid = LanguageModelDataset(\r\n",
    "            path=valid_fn,\r\n",
    "            fields=[('text', self.text)],\r\n",
    "            max_length=max_length\r\n",
    "        )\r\n",
    "\r\n",
    "\r\n",
    "        self.train_iter = data.BucketIterator(\r\n",
    "            train,\r\n",
    "            batch_size=batch_size,\r\n",
    "            device='cuda:%d' % device if device >= 0 else 'cpu',\r\n",
    "            shuffle=shuffle,\r\n",
    "            sort_key=lambda x: -len(x.text),\r\n",
    "            sort_within_batch=True\r\n",
    "        ) \r\n",
    "\r\n",
    "        self.valid_iter = data.BucketIterator(\r\n",
    "            valid,\r\n",
    "            batch_size=batch_size,\r\n",
    "            device='cuda:%d' % device if device >= 0 else 'cpu',\r\n",
    "            shuffle=shuffle,\r\n",
    "            sort_key=lambda x: -len(x.text),\r\n",
    "            sort_within_batch=True\r\n",
    "        )\r\n",
    "\r\n",
    "\r\n",
    "        self.text.build_vocab(train, max_size=max_vocab)\r\n",
    "\r\n",
    "\r\n",
    "class LanguageModelDataset(data.Dataset):\r\n",
    "    def __init__(self, path, fields, max_length=None, **kwargs):\r\n",
    "        if not isinstance(fields[0], (tuple, list)):\r\n",
    "            fields = [('text', fields[0])]\r\n",
    "\r\n",
    "        \r\n",
    "        examples = []\r\n",
    "\r\n",
    "        with open(path) as f:\r\n",
    "            for line in f:\r\n",
    "                if line in f:\r\n",
    "                    line = line.strip()\r\n",
    "                    if max_length and max_length < len(line.split()):\r\n",
    "                        continue \r\n",
    "                    if line != \"\":\r\n",
    "                        examples.append(data.Example.fromlist([line], fields))\r\n",
    "\r\n",
    "        super(LanguageModelDataset, self).__init__(examples, fields, **kwargs)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'torchtext.data' has no attribute 'Dataset'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d8b636e0062e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mLanguageModelDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Dataset'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('default': conda)"
  },
  "interpreter": {
   "hash": "c241ec60e7167152c8218504a6393589de3a2bb3e6995b097bc5c55e5bb99b8c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}