{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro text mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2DtecjUViOi",
        "outputId": "cd26fc72-b847-487c-b6a2-3324eaf5e952"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 71.5 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrKNGvF0WXoQ",
        "outputId": "dd60f1cf-67cf-461d-e0cc-a01ac223e3fa"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51pokuacWYvt"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjh51vfsXmYP",
        "outputId": "ab62cfab-39a6-4a26-c873-d48b4d384271"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unoz-jK_X6h6"
      },
      "source": [
        "word_tokenize는 Don't 를 Do, n't로 구분한 것을 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCH8ICbzWcXW",
        "outputId": "deffe63e-394d-4316-9eae-2e4db75c98a2"
      },
      "source": [
        "sentence = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "print(word_tokenize(sentence))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_kZ4Ot-YCrW"
      },
      "source": [
        "wordPunctTokenizer 는 Don't를 Don,',t 로 구분한 것을 볼 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKqcA7v5Xhhc"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwqSuqQOYNS7",
        "outputId": "05ae51bb-f0a5-43d1-8223-2b83b333efca"
      },
      "source": [
        "print(WordPunctTokenizer().tokenize(sentence))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l4rvITXZxZj"
      },
      "source": [
        "1. 하이픈으로 구성된 단어는 하나로 유지된다.\n",
        "2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0--t2rjYRDV"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EDZP-mgZ6yl",
        "outputId": "381378d1-f10e-4dd8-b187-0fdf251f8dee"
      },
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "text = \"Starting a home-based restaurant may be an ideal. It doesn't have a food chain or restaurant of their own.\"\n",
        "print(tokenizer.tokenize(text))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'It', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnMv7eYSaZVT"
      },
      "source": [
        "POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cgegb5oaHCi",
        "outputId": "ef6a17cd-434b-4e2e-e20c-eeb5fe6575ea"
      },
      "source": [
        "text = \"I am actively ooking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "print(word_tokenize(text))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'actively', 'ooking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybcMfTxdayFe",
        "outputId": "7e944f66-8a41-4745-cbcf-210f78fba45e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCMJ3xqUalj1",
        "outputId": "a4aa0937-0398-4520-c61d-d8d57790fae6"
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "pos = word_tokenize(text)\n",
        "pos_tag(pos)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('actively', 'RB'),\n",
              " ('ooking', 'VBG'),\n",
              " ('for', 'IN'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('students', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('and', 'CC'),\n",
              " ('you', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('student', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqV4W93ra4fN"
      },
      "source": [
        "Okt : SNS에 조금 더 특화된 형태소 분석기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOiWnSw9a5r-",
        "outputId": "6716a44d-1cc0-402d-de7a-c7b533ef7c10"
      },
      "source": [
        "from konlpy.tag import Okt \n",
        "okt = Okt()\n",
        "sentence = \"이 여름 다시 한번 설레고 싶다. 그 여름을 틀어줘. 싹쓰리\"\n",
        "print(okt.morphs(sentence))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '여름', '다시', '한번', '설레고', '싶다', '.', '그', '여름', '을', '틀어줘', '.', '싹', '쓰리']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tash8bBobQoI",
        "outputId": "a63f82df-273c-48dc-f2a6-dad0c77c9d83"
      },
      "source": [
        "print(okt.pos(sentence)) # pos tagging"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('이', 'Noun'), ('여름', 'Noun'), ('다시', 'Noun'), ('한번', 'Noun'), ('설레고', 'Adjective'), ('싶다', 'Verb'), ('.', 'Punctuation'), ('그', 'Noun'), ('여름', 'Noun'), ('을', 'Josa'), ('틀어줘', 'Verb'), ('.', 'Punctuation'), ('싹', 'Noun'), ('쓰리', 'Adjective')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkywfoPHbXG8",
        "outputId": "763042ba-f4d4-4344-c1ae-21a470e4da19"
      },
      "source": [
        "print(okt.nouns(sentence)) # 명사 추출"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '여름', '다시', '한번', '그', '여름', '싹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWNH3Ck7bYxd"
      },
      "source": [
        "from konlpy.corpus import kolaw "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVRT0EnabyWL"
      },
      "source": [
        "Law Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w_8SXPPBbpB7",
        "outputId": "f8bd6340-8545-48e2-a08c-6d5dacc3487b"
      },
      "source": [
        "law_corpus = kolaw.open('constitution.txt').read()\n",
        "law_corpus[:50]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'대한민국헌법\\n\\n유구한 역사와 전통에 빛나는 우리 대한국민은 3·1운동으로 건립된 대한민국임'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhfz7qgQbuKE",
        "outputId": "e268bbfc-8c86-42b3-e052-24a01bff21c2"
      },
      "source": [
        "okt.pos(law_corpus[:50])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('대한민국', 'Noun'),\n",
              " ('헌법', 'Noun'),\n",
              " ('\\n\\n', 'Foreign'),\n",
              " ('유구', 'Noun'),\n",
              " ('한', 'Josa'),\n",
              " ('역사', 'Noun'),\n",
              " ('와', 'Josa'),\n",
              " ('전통', 'Noun'),\n",
              " ('에', 'Josa'),\n",
              " ('빛나는', 'Verb'),\n",
              " ('우리', 'Noun'),\n",
              " ('대', 'Modifier'),\n",
              " ('한', 'Modifier'),\n",
              " ('국민', 'Noun'),\n",
              " ('은', 'Josa'),\n",
              " ('3', 'Number'),\n",
              " ('·', 'Punctuation'),\n",
              " ('1', 'Number'),\n",
              " ('운동', 'Noun'),\n",
              " ('으로', 'Josa'),\n",
              " ('건립', 'Noun'),\n",
              " ('된', 'Verb'),\n",
              " ('대한민국', 'Noun'),\n",
              " ('임', 'Noun')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reacxMw1cIVv"
      },
      "source": [
        "stop word 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esR07CUhcBaA"
      },
      "source": [
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwoOeewjm4J_",
        "outputId": "48136e5c-1cd1-4ca4-990d-09fc7c937274"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm96-V-qcRb2"
      },
      "source": [
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Ph33sGm1iU"
      },
      "source": [
        "example = \"Family is not an important thing. It's everything.\"\n",
        "word_tokens = word_tokenize(example)\n",
        "result = []\n",
        "for word in word_tokens:\n",
        "  if word not in stop_words:\n",
        "    result.append(word)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsd6fiNJpxy9",
        "outputId": "afae5397-0b44-4123-ca3f-40132674ae6c"
      },
      "source": [
        "result"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZUF6jsYqMtR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}